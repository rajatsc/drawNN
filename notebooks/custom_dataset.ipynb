{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torchvision import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch** ability to easily craft a **custom Dataset object** which can then be used with the **built-in DataLoader** to feed data when training a model.**Custom datasets** inherits from the base Dataset class. We need to define three functions in this custom class.  \n",
    "\n",
    "PyTorch gives you the freedom to pretty much do anything with the Dataset class so long as you override three of the subclass functions:  \n",
    "* the `__init__()`  function is where the initial logic happens like reading a csv, assigning transforms etc.\n",
    "* the `__len__` function which returns the size of the dataset, and\n",
    "* the `__getitem__` function which returns a sample from the dataset given an index.  \n",
    "\n",
    "Good practice for PyTorch datasets is that you keep in mind how the dataset will scale with more and more samples and, therefore, we do not want to store too many tensors in memory at runtime in the Dataset object. Instead, we will form the tensors as we iterate through the samples list, trading off a bit of speed for memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hot encoding** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class myDataset(data.Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        \n",
    "        self.transform = None\n",
    "        self.img_path = img_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        # of how many examples(images?) you have\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    def __getitem(self, index):\n",
    "        \"\"\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the **first step** we create our constructor and we set the transformations we want to make and the directory containing all the images as arguments to the constructor â€” inside the constructor just in case you typed the wrong directory name we are going to create a condition statement to catch such blunder.  \n",
    "\n",
    "The **second step** is to create the length method which will return to us the length of our dataset.  \n",
    "\n",
    "The **third step** is to create a function to get the files by id and return them, because we save memory by not loading all files to memory, making our code more efficient and putting every resource available to good use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
